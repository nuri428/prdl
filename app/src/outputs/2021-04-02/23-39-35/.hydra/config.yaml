tokenizer:
  data_path: ../datasets/wiki
  sample_rate: 0.1
  pretokenizer_type:
  - khaiii
  - mecab
  tokenizer_type:
  - bbpe
  - cbpe
  - wp
  vocab_size: 10000
  min_frequency: 2
  special_tokens: []
